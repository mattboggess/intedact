{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intedact import univariate_eda_interact\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mboggess/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mboggess/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are needed for text summaries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Diamonds Dataset\n",
    "\n",
    "The first example we will use is the classic diamonds dataset packaged with ggplot as well as seaborn. This first example is great for getting introduced to the basic discrete and continuous summaries.\n",
    "\n",
    "Recommended Explorations:\n",
    "  - Try playing with number of bins on carat\n",
    "  - Try removing outliers for the x, y, and z variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset(\"diamonds\")\n",
    "# Ordinal categorical variables need to be explicitly overwritten\n",
    "data[\"cut\"] = pd.Categorical(data[\"cut\"], categories=[\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"], ordered=True)\n",
    "data[\"color\"] = pd.Categorical(data[\"color\"], categories=[\"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"], ordered=True)\n",
    "data[\"clarity\"] = pd.Categorical(data[\"clarity\"], categories=[\"I1\", \"SI1\", \"SI2\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bf5155c4bd49e8801abb03e32d0493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Column: Column to be plotted', options=('carat', 'cut', 'color', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "univariate_eda_interact(data, notes_file=\"diamonds.json\", figure_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Tidy Tuesday GDPR Violations\n",
    "\n",
    "Recommended Explorations:\n",
    "- Try using a log transform on the price column.\n",
    "- Check out the date column for an example of a datetime summary. Try setting the lower quantile option to .06 so you can see the main time series.\n",
    "- Check out the summary column for an example of a text summary. By default, doesn't compute top ngrams so you can check the 'Plot most common ngrams' option to plot the top unigrams-trigrams. Also, since text tokenizing can be time consuming, it turns auto updating off so you have to press the 'Run Interact' button to update the summary when control options are changed.\n",
    "- Check out the article_violated column for an example of a collections summary\n",
    "- Check out the source column for an example of a url summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_violations.tsv\", sep=\"\\t\")\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "# Collection columns must be encoded as a Python iterable\n",
    "data[\"article_violated\"] = data[\"article_violated\"].apply(lambda x: x.split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0641ecce85f34b23aface48cb7fc6866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Column: Column to be plotted', options=('id', 'picture', 'name', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "univariate_eda_interact(data, notes_file=\"gdpr_violations.json\", figure_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 - Tidy Tuesday Tweets\n",
    "\n",
    "Here's a large social media dataset with many columns. Try seeing how it is to explore a larger dataset with many columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/tidytuesday_tweets/data.csv\")\n",
    "data[\"created_at\"] = pd.to_datetime(data[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3ed93bdeb445ffb25d9b4a6d7988ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Column: Column to be plotted', options=('week', 'user_id', 'status…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "univariate_eda_interact(data, notes_file=\"tidy_tuesday_tweets.json\", figure_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intedact",
   "language": "python",
   "name": "intedact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
